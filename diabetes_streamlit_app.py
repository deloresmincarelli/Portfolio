# This script:
# Connects to a sqlite database
# Displays a web page interface 
# Prompts the user for a question regarding database tables
# User is prompted for a natural language question.
# Script uses the OpenAI large language model (LLM) -- SUBSCRIPTION REQUIRED!
# The LLM interprets the request and converts to sql, INCLUDING JOINS!
# The sql generated by the LLM is run in pandas to generate the response
# Displays the results in text form, in a table form, and provides the SQL query generated

# Ref:
# BUSINESS SCIENCE UNIVERSITY - 
# LEARNING LAB 84: AI-POWERED LEAD SCORING APP
# STREAMLIT APP
# ----

# RUN APP:
# In Terminal window, select drop down carrot and choose Git Bash.
# type: streamlit run diabetes_streamlit_app.py

# LIBRARIES ----

import streamlit as st
from streamlit_chat import message

import pandas as pd
import sqlalchemy as sql
import os

from langchain import OpenAI
from langchain.sql_database import SQLDatabase
from langchain.chains import SQLDatabaseChain

# SET YOUR OPENAI API KEY ----
# this is a paid subscription to OpenAI, and saved as an environment variable
# os.environ["OPENAI_API_KEY"] = "YOUR_API_KEY"

# CONNECT TO DATABASE ----
sql_engine = sql.create_engine("sqlite:///DIABETES_DATABASE")
conn = sql_engine.connect()
# pd.read_sql_table('DIABETES_PREDICTIONS_TABLE', conn)


metadata = sql.MetaData()

metadata.reflect(bind=sql_engine)

metadata.tables.keys()

# pd.read_sql_table('DIABETES_PREDICTIONS_TABLE', conn)

# LLMS ----
# temperature controls randomness; value of 0 is deterministic & repetitive & no randomness & no creativity

llm = OpenAI(
    temperature    = 0, 
    max_tokens     = 256,
    openai_api_key = os.getenv("OPENAI_API_KEY")
)

# uses langchang function to set up db
db = SQLDatabase(engine=sql_engine)

sql_chain_with_steps = SQLDatabaseChain.from_llm(
    llm                       = llm, 
    db                        = db, 
    verbose                   = True,
    use_query_checker         = True,
    return_intermediate_steps = True,
)

# FUNCTIONS ----

# We will get the user's input by calling the get_text function
# st = streamlit
def get_text():
    input_text = st.text_area("You: ","Type question here:", key="input")
    return input_text

# We will generate the response by calling the generate_response function
def generate_chat_response(prompt):
    
    # Generate the response
    res = sql_chain_with_steps(prompt)
    
    # the answer to the prompt
    chatbot_response = res['result']
    
    # the sql generated by the llm ai tool
    chatbot_sql_code = res['intermediate_steps'][1]
    
    # pass the sql to pandas to generate the response in table format
    chatbot_sql_query_df = pd.read_sql_query(sql.text(chatbot_sql_code), conn)
    
    chat_response = [
        st.text(chatbot_response), 
        st.dataframe(chatbot_sql_query_df),
        st.code(chatbot_sql_code, language='sql', line_numbers=True),
    ]
    
    print(chatbot_response)
    
    return chat_response

# APP ----

st.set_page_config(layout="wide")

st.title("Diabetes Analyzer")

col1, col2 = st.columns(2)

with col1:
    st.header("Diabetes Patient Data")
    
    tab1, tab2 = st.tabs(["Diabetes Predictions", "Emergency Rm Visits"])

    with tab1:
        df = pd.read_sql_table('DIABETES_PREDICTIONS_TABLE', conn)
        st.dataframe(df)
    
    with tab2:
        df = pd.read_sql_table('PATIENT_ER_VISITS_TABLE', conn)
        st.dataframe(df)
    
#     # with tab3:
#     #     df = pd.read_sql_table('transactions', conn)
#     #     st.dataframe(df)
    
with col2:
        
    st.header("Ask me anything about the diabetes data")

        # Storing the chat
    if 'generated' not in st.session_state:
        st.session_state['generated'] = []

    if 'past' not in st.session_state:
        st.session_state['past'] = []
            
    user_input = get_text()

    if user_input:
        output = generate_chat_response(user_input)
        # store the output 
        st.session_state.past.append(user_input)
        st.session_state.generated.append(output)

    if st.session_state['generated']:
            
        for i in range(len(st.session_state['generated'])-1, -1, -1):
            message(
                st.session_state["generated"][i], 
                key=str(i),
                is_table=False,
                allow_html=True
            )
            message(
                st.session_state['past'][i], 
                is_user=True, 
                key=str(i) + '_user',
                allow_html=True
            )

conn.close()